import streamlit as st
import tempfile
import os
from chat import set_custom_prompt
from chat import gemini_bot
from pdf_processor import PDFDatabaseManager
import shutil
import time

vector_db_path = "vectorstores/db_faiss"
hash_store_path = "vectorstores/hashes.json"
pdf_data_path = ''

manager = PDFDatabaseManager(pdf_data_path, vector_db_path, hash_store_path)

def main():
    # C·∫•u h√¨nh trang
    st.set_page_config(page_title="ChatPDF", page_icon='ü§ñ')
    st.header("Vietnamese PDF Chat")

    # Giao di·ªán ng∆∞·ªùi d√πng cho vi·ªác nh·∫≠p c√¢u h·ªèi
    user_question = st.chat_input("Ask a Question from the PDF Files")

    if "history_global" not in st.session_state:
        st.session_state.history_global = []

    with st.sidebar:
        st.title("Upload PDF")
        pdf_docs = st.file_uploader("You can upload multiple PDFs", type="pdf", accept_multiple_files=True)
        if st.button("Submit & Process"):
            if pdf_docs:
                with st.spinner("Processing..."):
                    status_placeholder = st.empty()
                    with tempfile.TemporaryDirectory() as temp_dir:
                        manager.pdf_data_path = temp_dir
                        for uploaded_file in pdf_docs:
                            file_path = os.path.join(temp_dir, uploaded_file.name)
                            with open(file_path, "wb") as f:
                                f.write(uploaded_file.getbuffer())

                        pdf_files = [f for f in os.listdir(temp_dir) if f.lower().endswith('.pdf')]
                        for pdf_file in pdf_files:
                            file_path = os.path.join(temp_dir, pdf_file)
                            if not manager.is_pdf_exists(file_path):
                                status_placeholder.write(f"T·ªáp {pdf_file} ch∆∞a c√≥ trong db. Processing...")
                                manager.update_db(file_path)
                            else:
                                status_placeholder.write(f"T·ªáp {pdf_file} ƒë√£ c√≥ trong db, g·ª≠i t·ªáp kh√°c.")
                    db = manager.load_existing_db()
                    if db is not None:
                        st.session_state.vector_db = db
                        st.success("PDFs processed and vector database created!")

                        time.sleep(3)
                        status_placeholder.empty()

            else:
                st.warning("No file selected")

    # Kh·ªüi t·∫°o l·ªãch s·ª≠ chat
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Hi·ªÉn th·ªã tin nh·∫Øn chat t·ª´ l·ªãch s·ª≠ tr√™n l·∫ßn ch·∫°y l·∫°i ·ª©ng d·ª•ng
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if user_question:
        if 'vector_db' in st.session_state:
            with st.chat_message("user"):
                st.markdown(user_question)

            # S·ª≠ d·ª•ng gemini_bot ƒë·ªÉ x√°c ƒë·ªãnh √Ω ƒë·ªãnh
            intent_prompt = (
                f"Ph√¢n lo·∫°i c√¢u h·ªèi sau: '{user_question}'. "
                f"Lo·∫°i n√†o trong s·ªë sau: 'h·ªèi v·ªÅ c√¢u h·ªèi tr∆∞·ªõc', 'h·ªèi v·ªÅ c√¢u tr·∫£ l·ªùi tr∆∞·ªõc', ho·∫∑c 'c√¢u h·ªèi m·ªõi'."
            )
            intent_response = gemini_bot.response(intent_prompt).strip().lower()

            if "h·ªèi v·ªÅ c√¢u h·ªèi tr∆∞·ªõc" in intent_response:
                last_question = get_last_message(role="user")
                response = f'B·∫°n v·ª´a h·ªèi: "{last_question}"' if last_question else "Kh√¥ng c√≥ c√¢u h·ªèi n√†o ƒë∆∞·ª£c t√¨m th·∫•y."
            elif "h·ªèi v·ªÅ c√¢u tr·∫£ l·ªùi tr∆∞·ªõc" in intent_response:
                last_answer = st.session_state.last_answer
                response = f'T√¥i v·ª´a tr·∫£ l·ªùi r·∫±ng: "{last_answer}"' if last_answer else "Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi n√†o ƒë∆∞·ª£c t√¨m th·∫•y."

            # X·ª≠ l√Ω c√¢u h·ªèi m·ªõi
            else:
                docs = st.session_state.vector_db.similarity_search(user_question, k=2)
                context = "\n\n".join([doc.page_content for doc in docs])

                prompt = set_custom_prompt()
                st.session_state.history_global.append(user_question + context)
                history_global_str = "\n".join(st.session_state.history_global)
                prompt_with_context = prompt.format(history_global=history_global_str, context=context, question=user_question)
                response = gemini_bot.response(prompt_with_context)

                # L∆∞u tr·ªØ c√¢u tr·∫£ l·ªùi cu·ªëi c√πng
                st.session_state.last_answer = response

                with st.chat_message('assistant'):
                    st.markdown(response)
                    with st.expander("Show Context", expanded=False):
                        st.write(context)

            # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi cho c√°c tr∆∞·ªùng h·ª£p kh√¥ng ph·∫£i c√¢u h·ªèi m·ªõi
            if "h·ªèi v·ªÅ c√¢u h·ªèi tr∆∞·ªõc" in intent_response or "h·ªèi v·ªÅ c√¢u tr·∫£ l·ªùi tr∆∞·ªõc" in intent_response:
                with st.chat_message('assistant'):
                    st.markdown(response)

            # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√† ph·∫£n h·ªìi c·ªßa tr·ª£ l√Ω v√†o l·ªãch s·ª≠ chat
            st.session_state.messages.append({"role": "user", "content": user_question})
            st.session_state.messages.append({"role": "assistant", "content": response})
        else:
            st.warning("H√£y ƒë∆∞a file c·ªßa b·∫°n l√™n tr∆∞·ªõc, ch√∫ng t√¥i s·∫Ω d·ª±a v√†o ƒë√≥ ƒë·ªÉ tr·∫£ l·ªùi")

def get_last_message(role):
    messages = st.session_state.get("messages", [])
    for message in reversed(messages):
        if message["role"] == role:
            return message["content"]
    return None

if __name__ == "__main__":
    main()