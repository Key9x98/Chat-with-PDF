import streamlit as st
from document_processor import DocumentProcessor
import tempfile
import os
from chat import set_custom_prompt
from chat import gemini_bot


def main():
    # C·∫•u h√¨nh trang
    st.set_page_config(page_title="ChatPDF", page_icon='ü§ñ')
    st.header("Vietnamese PDF Chat")

    # Giao di·ªán ng∆∞·ªùi d√πng cho vi·ªác nh·∫≠p c√¢u h·ªèi
    user_question = st.chat_input("Ask a Question from the PDF Files")

    # Bi·∫øn ƒë√°nh d·∫•u xem c√≥ t·ªáp n√†o ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n kh√¥ng
    pdf_docs = None
    history_global = []
    with st.sidebar:
        st.title("Upload PDF")
        pdf_docs = st.file_uploader("You can upload multiple PDFs", type="pdf", accept_multiple_files=True)
        if st.button("Submit & Process"):
            if pdf_docs:
                with st.spinner("Processing..."):
                    with tempfile.TemporaryDirectory() as temp_dir:
                        # Save uploaded files to the temporary directory
                        for uploaded_file in pdf_docs:
                            file_path = os.path.join(temp_dir, uploaded_file.name)
                            with open(file_path, "wb") as f:
                                f.write(uploaded_file.getbuffer())
                        processor = DocumentProcessor(temp_dir, "vectorstores/db_faiss")
                        db = processor.run()
                    st.session_state.vector_db = db
                    st.success("PDFs processed and vector database created!")
            else:
                st.warning("No file selected")

    # Kh·ªüi t·∫°o l·ªãch s·ª≠ chat
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Hi·ªÉn th·ªã tin nh·∫Øn chat t·ª´ l·ªãch s·ª≠ tr√™n l·∫ßn ch·∫°y l·∫°i ·ª©ng d·ª•ng
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if user_question:
        # Ki·ªÉm tra xem c√≥ t·ªáp n√†o ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n ch∆∞a
        if 'vector_db' in st.session_state:
            # Hi·ªÉn th·ªã tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng trong h·ªôp tin nh·∫Øn chat
            with st.chat_message("user"):
                st.markdown(user_question)

            docs = st.session_state.vector_db.similarity_search(user_question, k=2)
            context = "\n\n".join([doc.page_content for doc in docs])
            prompt = set_custom_prompt()
            history_global.append(user_question + context)
            history_global_str = "\n".join(history_global)
            prompt_with_context = prompt.format(history_global= history_global_str, context=context, question=user_question)
            response = gemini_bot.response(prompt_with_context)


            # Hi·ªÉn th·ªã ph·∫£n h·ªìi trong h·ªôp tin nh·∫Øn chat
            with st.chat_message('assistant'):
                st.markdown(response)

            # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ chat
            st.session_state.messages.append({"role": "user", "content": user_question})
            # Th√™m ph·∫£n h·ªìi c·ªßa tr·ª£ l√Ω v√†o l·ªãch s·ª≠ chat
            st.session_state.messages.append({"role": "assistant", "content": response})
        else:
            st.warning("H√£y ƒë∆∞a file c·ªßa b·∫°n l√™n tr∆∞·ªõc, ch√∫ng t√¥i s·∫Ω d·ª±a v√†o ƒë√≥ ƒë·ªÉ tr·∫£ l·ªùi")

if __name__ == "__main__":
    main()
